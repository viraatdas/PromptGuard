import { RedactionsMap } from '../sanitizer';
import { logger } from '../logger';

/**
 * Process LLM output to rehydrate PII or perform additional filtering
 * @param output The raw output from the LLM
 * @param redactions The map of redactions from the input sanitizer
 * @returns Processed output with rehydrated PII if applicable
 */
export const processOutput = async (
  output: string,
  redactions: RedactionsMap
): Promise<string> => {
  try {
    let processedOutput = output;
    
    // If no redactions, return the original output
    if (!redactions || Object.keys(redactions).length === 0) {
      return output;
    }
    
    // Rehydrate redacted content
    for (const [placeholder, redaction] of Object.entries(redactions)) {
      // Simple replacement of placeholder with original text
      // In a real-world scenario, you might want to be more careful about this
      // For example, you might want to verify that it's safe to rehydrate this content
      processedOutput = processedOutput.replace(
        new RegExp(placeholder, 'g'),
        redaction.originalText
      );
    }
    
    // Log the number of rehydrated elements
    logger.info(`Rehydrated ${Object.keys(redactions).length} PII elements in the output`);
    
    // Optional: Add additional filters here (e.g., for brand safety)
    // This could include filtering out inappropriate content generated by the model
    // e.g., processedOutput = filterInappropriateContent(processedOutput);
    
    return processedOutput;
  } catch (error) {
    logger.error(`Error processing output: ${error instanceof Error ? error.message : 'Unknown error'}`);
    // In case of error, return the original output
    return output;
  }
};

/**
 * Extract PII from the output that wasn't in the input
 * This can be used to detect if the model is hallucinating PII
 * @param output The raw output from the LLM
 * @returns Map of detected PII in the output
 */
export const detectOutputPII = async (output: string): Promise<Record<string, string[]>> => {
  // This is a placeholder function
  // In a real implementation, you would use the same PII detection logic from the sanitizer
  // And return any detected PII in the output
  
  // For example:
  // const emailRegex = /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g;
  // const emails = output.match(emailRegex) || [];
  
  // const phoneRegex = /(?:\+\d{1,3}[- ]?)?\(?\d{3}\)?[- ]?\d{3}[- ]?\d{4}/g;
  // const phones = output.match(phoneRegex) || [];
  
  // Return a structure of detected PII
  // return { emails, phones };
  
  // For now, we'll just return an empty result
  return {};
};

/**
 * Filter specific words or phrases from the output
 * @param output The text to filter
 * @param filterList List of words or phrases to filter
 * @param replacement What to replace filtered content with
 * @returns Filtered output
 */
export const filterContent = (
  output: string,
  filterList: string[],
  replacement: string = '[FILTERED]'
): string => {
  let filteredOutput = output;
  
  for (const term of filterList) {
    // Create a case-insensitive RegExp for the term
    const regex = new RegExp(term, 'gi');
    filteredOutput = filteredOutput.replace(regex, replacement);
  }
  
  return filteredOutput;
}; 